{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import os,time\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import math\n",
    "import utils\n",
    "from utils import Scoring\n",
    "import matplotlib.pyplot as plt\n",
    "from dataLoader import reshape_folds\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      fbank\n",
       "1                  log-fbank\n",
       "2                    mfcc_26\n",
       "3                    mfcc_13\n",
       "4            fbank_log-fbank\n",
       "5              fbank_mfcc_13\n",
       "6          log-fbank_mfcc_13\n",
       "7    fbank_log-fbank_mfcc_13\n",
       "8                  mfcc_13_d\n",
       "9                 mfcc_13_dd\n",
       "Name: feature, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel (r'../logs/pretrained.xlsx')\n",
    "input_features = df[\"feature\"].iloc[:]\n",
    "input_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results From One Specific Input Feature\n",
    "\n",
    "Select one feature from the upper list for McNemer Test with baseline models and put the name in the \"Selected Feature\" variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mfcc_13_dd --- EPOCH ---- ( 18 )----\n",
      "Validation loss -  0.5186641216278076\n",
      "TN: 127 FP: 19 FN: 37 TP: 101\n",
      "Sensitivity: 0.732 Specificity: 0.870 Precision: 0.842 F1: 0.783 MACC 0.801 Accuracy 0.803\n"
     ]
    }
   ],
   "source": [
    "feature = \"mfcc_13_dd\" # Selected Feature\n",
    "    \n",
    "index = [i for i, feat in enumerate(input_features) if(feat==feature)][0]\n",
    "\n",
    "class paramClass():\n",
    "    def __init__(self):\n",
    "        self.epoch = df[\"epoch\"][index]\n",
    "        self.batch_size = df[\"batch_size\"][index]\n",
    "        self.inp = df[\"inp\"][index]\n",
    "        self.base_lr = df[\"base_lr\"][index]\n",
    "        self.max_lr = df[\"max_lr\"][index]\n",
    "        self.step_size = df[\"step_size\"][index]\n",
    "        self.checkpoint = '../logs/' + self.inp + \"/checkpoints/\"\n",
    "param = paramClass()\n",
    "\n",
    "data_file = \"../data/feature/train_val_npzs/\" + param.inp + \"_train_val_data.npz\"\n",
    "data = np.load(data_file)\n",
    "\n",
    "x_val = data['x_val_mfcc']\n",
    "y_val = data['y_val']\n",
    "val_parts = data['val_parts']\n",
    "val_wav_files = data['val_wav_files']\n",
    "\n",
    "x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2], 1)\n",
    "\n",
    "#--- Reshape the folds\n",
    "_, [y_val] = reshape_folds([], [y_val])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_val = to_categorical(y_val, num_classes = 2)\n",
    "\n",
    "from model import resnet_extractor, abn_classifier\n",
    "nodes = [16, 32, 64, 128]\n",
    "num_layers = 2\n",
    "model_fe = resnet_extractor(1, None, param.inp, nodes, num_layers).cuda()\n",
    "model_abn = abn_classifier(model_fe.out_features, 2, dropout = None).cuda()\n",
    "\n",
    "e = param.epoch - 1\n",
    "checkpoint_fe = param.checkpoint + str(e+1) + \"_saved_fe_model.pth.tar\"\n",
    "model_fe.load_state_dict(torch.load(checkpoint_fe)[\"state_dict\"])\n",
    "checkpoint_abn = param.checkpoint + str(e+1) + \"_saved_cls_model.pth.tar\"\n",
    "model_abn.load_state_dict(torch.load(checkpoint_abn)[\"state_dict\"])\n",
    "\n",
    "epoch_loss = torch.load(checkpoint_fe)[\"loss\"]\n",
    "val_loss_load = torch.load(checkpoint_fe)[\"val_loss\"]\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\n\" + feature + \" --- EPOCH ---- ( \" + str(e+1) + \" )----\")\n",
    "\n",
    "model_fe.eval()\n",
    "model_abn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    cls_pred = None\n",
    "    cls_val = None\n",
    "    total_features = np.array([])\n",
    "    epoch_val_loss = 0\n",
    "    s = 0\n",
    "    for i, part in enumerate(val_parts):\n",
    "        x,y = torch.from_numpy(x_val[s:s+part]),torch.from_numpy(y_val[s:s+part])\n",
    "        s = s + part\n",
    "\n",
    "        if(len(x) == 0): # If no bits are found\n",
    "            continue\n",
    "\n",
    "        x,y = Variable(x),Variable(y)\n",
    "        x = x.type(torch.FloatTensor).cuda()\n",
    "\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2])\n",
    "        y = torch.tensor(np.array(y).reshape(-1, 2)).cuda().float()\n",
    "\n",
    "        features = model_fe(x)\n",
    "        cls = model_abn(features)\n",
    "\n",
    "        val_loss = loss_fn(cls, torch.argmax(y,dim=1))\n",
    "\n",
    "        if(i==0): total_features = features.cpu().numpy()\n",
    "        else: total_features = np.concatenate((total_features, features.cpu().numpy()))\n",
    "\n",
    "        if(cls_pred is None):\n",
    "            cls_pred = cls\n",
    "            cls_val = y\n",
    "        else:\n",
    "            cls_pred = torch.cat((cls_pred,cls))\n",
    "            cls_val = torch.cat((cls_val,y))\n",
    "\n",
    "        epoch_val_loss = epoch_val_loss + val_loss\n",
    "        del x, y, features, cls, val_loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_val_loss = epoch_val_loss/len(val_parts)\n",
    "\n",
    "    print(\"Validation loss - \", str(epoch_val_loss.item()))\n",
    "\n",
    "domain = np.asarray(val_wav_files).reshape((-1, 1))\n",
    "score_log = Scoring(e + 1)\n",
    "_, true, pred_proposed, _ = score_log.log_score(cls_pred, cls_val, val_parts, \n",
    "        y_domain = domain, list_out=True)\n",
    "\n",
    "del model_fe, model_abn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Baseline Model Result (heartnet / potes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../logs/baseline_predictions.npz\")\n",
    "pred_potes = data[\"pred_potes\"]\n",
    "pred_heartnet = data[\"pred_heartnet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "def McnemerStats(true,pred1,pred2,threshold = 0.05, lab1='model 1', lab2='model 2'):\n",
    "    \"\"\"\n",
    "    true: true labels of the data. \n",
    "    pred1: predicted values from model 1 ## generated from block 8\n",
    "    pred2: predicted values from model 2 ## generated from block 8\n",
    "    \"\"\"\n",
    "    pred1 = 1*(np.asarray(pred1) > 0.5)\n",
    "    pred2 = 1*(np.asarray(pred2) > .5)\n",
    "    true = np.asarray(true)\n",
    "    \n",
    "    mc_table = mcnemar_table(y_target=true, \n",
    "                   y_model1=pred1, \n",
    "                   y_model2=pred2)\n",
    "    if(np.min(mc_table)<25):\n",
    "        result = mcnemar(mc_table, exact=True)\n",
    "    else:\n",
    "        result = mcnemar(mc_table, exact=False, correction=True)\n",
    "    print('statistic=%.10f, p-value=%.10f' % (result.statistic, result.pvalue))\n",
    "    # interpret the p-value\n",
    "    alpha = threshold\n",
    "    if result.pvalue > alpha:\n",
    "        print('Same proportions of errors, models make similar error (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different proportions of errors, error rates are different (reject H0)')\n",
    "    return result.statistic,result.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with heartnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=35.0000000000, p-value=1.0000000000\n",
      "Same proportions of errors, models make similar error (fail to reject H0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35.0, 1.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "McnemerStats(true,pred_proposed, pred_heartnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with potes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=0.0166666667, p-value=0.8972789613\n",
      "Same proportions of errors, models make similar error (fail to reject H0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.016666666666666666, 0.897278961260083)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "McnemerStats(true,pred_proposed, pred_potes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kagg_p",
   "language": "python",
   "name": "kagg_p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
